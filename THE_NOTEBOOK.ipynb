{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Predicting Extreme Poverty on a country-scale__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import warnings\n",
    "import plots as plot\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import category_encoders as ec\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index\n",
    "1. Data Exploration and Data Preparation\n",
    "    * 1.1 Data Transformation\n",
    "    * 1.2 Target Column\n",
    "    * 1.3 Feature Overview\n",
    "    * 1.4 Data Imputation\n",
    "    * 1.5 Data Vizualization & Exploration\n",
    "2. Answering the 3 Questions\n",
    "    * 2.1 What percentage of the world population lives in extreme poverty?\n",
    "    * 2.2 Which characteristics are predictive for countries with large populations living in extreme poverty?\n",
    "    * 2.3 Which characteristics are predictive for populations emerging from extreme poverty?\n",
    "3. Conclusions\n",
    "    * 3.1 Comparing Q1 and Q2\n",
    "4. Future Work\n",
    "    * 4.1 More Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Data Exploration and Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data Set\n",
    "blabla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Data Transformation\n",
    "TODO How was it transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ SOURCE CSV\n",
    "raw = pd.read_csv(\"unesco_poverty_dataset.csv\") \n",
    "keys = raw.DEMO_IND.unique() \n",
    "\n",
    "# DEFINE BASE CSV\n",
    "base = raw[['LOCATION', 'TIME']]\n",
    "\n",
    "# FOR EVERY VAR JOIN ON LOCATION & TIME \n",
    "for i in range(0,len(keys)):\n",
    "    loop = raw.loc[raw.DEMO_IND == keys[i]]\n",
    "    base = pd.merge(base, loop[['LOCATION', 'TIME', 'Value']],  how='left', left_on=['LOCATION','TIME'], right_on = ['LOCATION','TIME']) \n",
    "    base.columns = base.columns.str.replace('Value', keys[i])\n",
    "\n",
    "# DROP DUPLICATES\n",
    "base = base.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Target Column\n",
    "_what is the target column supposed to be?_    \n",
    "There are 3 different metrics to count the GNI of a state: __LCU, Atlas, PPP__, so which is the correct one?   \n",
    "\n",
    "The Poverty Threshold changed throughout the years: \n",
    "* 1/day in 1996 (measure unknown)   \n",
    "* 1.25/day in 2005 (measure unknown, presumably Atlas)   \n",
    "* 1.9/day in 2015 (PPP)   \n",
    "_the $ values being average per capita income of a person per day_   \n",
    "\n",
    "[World Bank Press Release, October 2015]('https://www.worldbank.org/en/news/press-release/2015/10/04/world-bank-forecasts-global-poverty-to-fall-below-10-for-first-time-major-hurdles-remain-in-goal-to-end-poverty-by-2030')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 1970-2019, all countries considered, 29.61 % have lived in extreme poverty at least once.\n"
     ]
    }
   ],
   "source": [
    "# SEPARATE INTO 3 SUB-TABLES: 1970-2004, 2005-2014, 2015-2019\n",
    "sub_0 = base[base['TIME'] < 2005]\n",
    "sub_1 = base[(base['TIME'] >= 2005) & (base['TIME'] < 2015)]\n",
    "sub_2 = base[base['TIME'] >= 2015]\n",
    "\n",
    "# WRITE TARGET VARIABLES\n",
    "sub_0['poverty'] = base['NY_GNP_PCAP_CN'].apply(lambda x: (x / 365) < 1)\n",
    "sub_1['poverty'] = base['NY_GNP_PCAP_CD'].apply(lambda x: (x / 365) < 1.25)\n",
    "sub_2['poverty'] = base['NY_GNP_PCAP_PP_CD'].apply(lambda x: (x / 365) < 1.9)\n",
    "\n",
    "# RE-CONCAT SUB-DATAFRAMES\n",
    "base = pd.concat([sub_0, sub_1, sub_2])\n",
    "\n",
    "# SHOW HOW MANY COUNTRIES WERE POOR AT LEAST ONCE\n",
    "poor = base[base['poverty'] == True]\n",
    "perc_poor_countries_ever = round(poor['LOCATION'].drop_duplicates().shape[0] / base['LOCATION'].drop_duplicates().shape[0] * 100,2)\n",
    "\n",
    "print('From 1970-2019, all countries considered,', perc_poor_countries_ever, '% have lived in extreme poverty at least once.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PLOT\n",
    "# plot.combined_line_chart(base.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Features\n",
    "bla bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GET DATA PER COLUMN\n",
    "na_percent = []\n",
    "na_total = []\n",
    "minimum = []\n",
    "maximum = []\n",
    "for col in base.columns:\n",
    "    na_percent.append(round(base[col].isna().sum() / base.shape[0] * 100, 2))\n",
    "    na_total.append(base[col].isna().sum())\n",
    "    minimum.append(base[col].min())\n",
    "    maximum.append(base[col].max())\n",
    "\n",
    "# GET VARIABLE DESCRIPTIONS\n",
    "descriptions = raw['Indicator'].drop_duplicates().tolist()\n",
    "descriptions.insert(0, 'LOCATION')\n",
    "descriptions.insert(1, 'TIME')\n",
    "descriptions.insert(38, 'poverty')\n",
    "\n",
    "features = pd.DataFrame(\n",
    "    {'descriptions': descriptions, \n",
    "    'na_percent': na_percent, \n",
    "    'na_total': na_total,\n",
    "    'minimum': minimum,\n",
    "    'maximum': maximum},\n",
    "    index=base.columns) \n",
    "\n",
    "# features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Data Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ TRANSFORMED CSV FILE\n",
    "raw = pd.read_csv(\"transformed.csv\")  \n",
    "feature_descriptions = pd.read_csv(\"feature_descriptions.csv\")\n",
    "\n",
    "# FEATURES WITH LESS THAN 50% MISSING VALUES\n",
    "features = feature_descriptions.where(feature_descriptions['na_percent']<=50.0).dropna(0)\n",
    "\n",
    "# ONLY DEMOGRAFIC FEATURES!\n",
    "#cols_to_drop = 7:13 + 18:25\n",
    "cols = features['Unnamed: 0'].tolist()\n",
    "cols = cols[0:7]+ cols[13:18] + [cols[25]]\n",
    "dataset = raw[cols]\n",
    "    \n",
    "by_country = dataset.groupby(by=dataset['LOCATION'])  \n",
    "dataset_full = pd.DataFrame(columns=cols)\n",
    "dataset_full2 = pd.DataFrame(columns=cols)\n",
    "\n",
    "\n",
    "for name, group in by_country :\n",
    "    tdf = pd.DataFrame(columns=cols)\n",
    "    tdf2 = pd.DataFrame(columns=cols) \n",
    "\n",
    "    tdf['TIME'] = group['TIME']\n",
    "    tdf['poverty'] = group['poverty']\n",
    "\n",
    "    # cols with all NaN values\n",
    "    all_null = group.isna().all()  \n",
    "    null_cols = all_null.where(all_null == 1).dropna(0).index.tolist()\n",
    "    tdf[null_cols] = 0\n",
    "\n",
    "    # cols for interpolation\n",
    "    cols_to_int = all_null.where(all_null == 0).dropna(0).index.tolist()[2:]\n",
    "    cols_to_int.remove('poverty')\n",
    "\n",
    "    tdf[cols_to_int] = group[cols_to_int].interpolate(method='linear', axis=0)\n",
    "    tdf['LOCATION'] = name \n",
    "\n",
    "    # fill the NaN values that were not interpolated\n",
    "    tdf.fillna(tdf.mean(), inplace=True)\n",
    "\n",
    "    # Another way to interpolate - take mean for the cols with all NaNs\n",
    "    tdf2 = group.interpolate(method ='linear', limit_direction ='forward', axis = 0)\n",
    "    tdf2 = tdf2.interpolate(method ='linear', limit_direction ='backward', axis = 0)\n",
    "    tdf2['LOCATION'] = name\n",
    "    tdf2.fillna(dataset.drop(labels=['LOCATION'], axis=1).mean(), inplace=True)\n",
    "    dataset_full2 = pd.concat([dataset_full2,tdf2])\n",
    "    \n",
    "    dataset_full = pd.concat([dataset_full,tdf])\n",
    "\n",
    "# NA -> mean    \n",
    "dataset_full2.sort_index(inplace=True)\n",
    "# NA -> 0\n",
    "dataset_full.sort_index(inplace=True)\n",
    "\n",
    "# dataset_full2.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Visualizations & Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Answering the Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - What percentage of the world population lives in extreme poverty?\n",
    "bla bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Which characteristics are predictive for countries with large populations living in extreme poverty?\n",
    "\n",
    "bla bla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Calssifier accuracy : 0.94262 +- 0.00034\n"
     ]
    }
   ],
   "source": [
    "# GROUND TRUTH AS NUMERIC\n",
    "y = dataset_full['poverty']\n",
    "y = y.apply(lambda x: 1 if x==True else 0)\n",
    "X_2 = dataset_full2.drop(labels=['LOCATION', 'poverty'], axis=1)\n",
    "\n",
    "# FUNCTIONS FOR ML \n",
    "def print_performance (classifier, X, y, scores= ['accuracy', 'precision', 'recall'], model=''):\n",
    "    for score in scores:\n",
    "        cv2 = cross_val_score(classifier, X, y, cv=10, scoring=score)\n",
    "        cv2_m = cv2.mean()\n",
    "        cv2_sd = cv2.std()\n",
    "        print(model + ' ' + score +\" : \" + str(round(cv2_m, 5))+ ' +- '+ str(round(cv2_sd, 5)))\n",
    "\n",
    "def r_classifier (X, y, alpha=1.0, fit_intercept=True, normalize=True, solver='auto', max_iter=1000, tol=0.0001) :\n",
    "    reg = linear_model.RidgeClassifier(alpha=alpha, fit_intercept=fit_intercept, normalize=normalize, max_iter=max_iter, tol=0.001, solver='auto', random_state=30)\n",
    "    print_performance(reg, X , y, model='Ridge Calssifier', scores= ['accuracy'])\n",
    "    reg.fit(X,y)\n",
    "    return reg   \n",
    "\n",
    "ridge_2 =  r_classifier(X_2,y, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the most predictive features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>absolute</th>\n",
       "      <th>relative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TIME</td>\n",
       "      <td>-0.001943</td>\n",
       "      <td>-0.075534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP_DYN_TFRT_IN</td>\n",
       "      <td>0.012889</td>\n",
       "      <td>0.501145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SP_DYN_LE00_IN</td>\n",
       "      <td>-0.003791</td>\n",
       "      <td>-0.147391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP_DYN_IMRT_IN</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.037497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP_POP_GROW</td>\n",
       "      <td>-0.005550</td>\n",
       "      <td>-0.215784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SP_RUR_TOTL_ZS</td>\n",
       "      <td>-0.000580</td>\n",
       "      <td>-0.022568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200151</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200345</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>200343</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>200144</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               col  absolute  relative\n",
       "0             TIME -0.001943 -0.075534\n",
       "1   SP_DYN_TFRT_IN  0.012889  0.501145\n",
       "2   SP_DYN_LE00_IN -0.003791 -0.147391\n",
       "3   SP_DYN_IMRT_IN  0.000964  0.037497\n",
       "4      SP_POP_GROW -0.005550 -0.215784\n",
       "5   SP_RUR_TOTL_ZS -0.000580 -0.022568\n",
       "6           200101  0.000000  0.000000\n",
       "7           200151  0.000001  0.000032\n",
       "8           200345 -0.000000 -0.000010\n",
       "9           200343  0.000001  0.000028\n",
       "10          200144 -0.000000 -0.000012"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2_coef = np.array(ridge_2.coef_)\n",
    "X2_cols = X_2.columns\n",
    "R2_relativ = R2_coef/np.abs(R2_coef).sum()\n",
    "table = {'col':X2_cols, 'absolute':[], 'relative':[]}\n",
    "\n",
    "# Fill into Dataframe\n",
    "for i in range(0,len(X2_cols)):\n",
    "    table['absolute'].append(round(R2_coef[0,i],6))\n",
    "    table['relative'].append(round(R2_relativ[0,i],6))\n",
    "    \n",
    "weights = pd.DataFrame.from_dict(table)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - Which characteristics are predictive for populations emerging from extreme poverty?\n",
    "bla bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
